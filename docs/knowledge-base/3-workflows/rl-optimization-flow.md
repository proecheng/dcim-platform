# RLæ·±åº¦å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æµç¨‹

> ä¸“åˆ©S5 - è‡ªé€‚åº”å‚æ•°ä¼˜åŒ–çš„å®Œæ•´é—­ç¯æµç¨‹

---

## æ¦‚è¿°

RL (Reinforcement Learning) ä¼˜åŒ–æ¨¡å—æ˜¯DCIMç³»ç»Ÿçš„æ ¸å¿ƒæ™ºèƒ½ç»„ä»¶ï¼Œé€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•å®ç°èŠ‚èƒ½æ–¹æ¡ˆçš„è‡ªé€‚åº”ä¼˜åŒ–ã€‚

### æ ¸å¿ƒä»·å€¼
- ğŸ¯ **è‡ªåŠ¨è°ƒå‚**: æ ¹æ®æ•ˆæœåé¦ˆè‡ªåŠ¨ä¼˜åŒ–æ–¹æ¡ˆå‚æ•°
- ğŸ“ˆ **æŒç»­æ”¹è¿›**: å­¦ä¹ å†å²ç»éªŒï¼Œè¶Šç”¨è¶Šå‡†
- âš¡ **å®æ—¶å“åº”**: å¯¹ç¯å¢ƒå˜åŒ–å¿«é€Ÿé€‚åº”

---

## æµç¨‹å›¾

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         MDP ç¯å¢ƒå»ºæ¨¡ (S5a)          â”‚
                    â”‚                                     â”‚
                    â”‚  çŠ¶æ€ S = [è´Ÿè½½, ç”µä»·, æªæ–½çŠ¶æ€,     â”‚
                    â”‚           è¾¾æˆç‡å†å², è®¾å¤‡å‚æ•°]      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         ç­–ç•¥ç½‘ç»œ (Actor)            â”‚
                    â”‚                                     â”‚
                    â”‚   è¾“å…¥: çŠ¶æ€å‘é‡ (64ç»´)              â”‚
                    â”‚   è¾“å‡º: åŠ¨ä½œå‘é‡ (å‚æ•°è°ƒæ•´é‡)         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       åŠ¨ä½œè§£ç  (S5e)                â”‚
                    â”‚                                     â”‚
                    â”‚  æ¸©åº¦è°ƒæ•´: Â±0.5â„ƒ                    â”‚
                    â”‚  åŠŸç‡åˆ†é…: Â±5%                      â”‚
                    â”‚  æ—¶æ®µåç§»: Â±30min                   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       åº”ç”¨ä¼˜åŒ–å»ºè®®                   â”‚
                    â”‚                                     â”‚
                    â”‚  ç”¨æˆ·ç¡®è®¤ â†’ ä¸‹å‘åˆ°æ§åˆ¶ç³»ç»Ÿ           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       æ•ˆæœç›‘æµ‹ (S4)                 â”‚
                    â”‚                                     â”‚
                    â”‚  é‡‡é›†å®é™…èƒ½è€— â†’ è®¡ç®—è¾¾æˆç‡           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       å¥–åŠ±è®¡ç®—                      â”‚
                    â”‚                                     â”‚
                    â”‚  R = è¾¾æˆç‡ - Î»1*èˆ’é€‚åº¦è¿è§„         â”‚
                    â”‚      - Î»2*å®‰å…¨è¿è§„                  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       åœ¨çº¿å­¦ä¹  (S5f)                â”‚
                    â”‚                                     â”‚
                    â”‚  æ›´æ–°ç­–ç•¥ç½‘ç»œæƒé‡                    â”‚
                    â”‚  è°ƒæ•´æ¢ç´¢ç‡                         â”‚
                    â”‚  ä¿å­˜ç»éªŒåˆ°å›æ”¾ç¼“å†²åŒº                â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    ä¸‹ä¸€å‘¨æœŸä¼˜åŒ–              â”‚
                              â”‚    (è¿”å›çŠ¶æ€é‡‡é›†)            â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## çŠ¶æ€ç©ºé—´è®¾è®¡ (S5a)

### çŠ¶æ€å‘é‡æ„æˆ

```python
state = {
    # è´Ÿè·æ•°æ® (16ç»´)
    "load_data": [P1, P2, ..., P16],  # è¿‡å»16å°æ—¶å¹³å‡åŠŸç‡

    # ç”µä»·æ—¶æ®µ (1ç»´)
    "price_period": 0|1|2|3|4,  # æ·±è°·/è°·/å¹³/å³°/å°–å³°

    # æªæ–½æ‰§è¡ŒçŠ¶æ€ (10ç»´)
    "measure_states": [s1, s2, ..., s10],  # 0=å¾…æ‰§è¡Œ, 1=æ‰§è¡Œä¸­, 2=å®Œæˆ

    # è®¾å¤‡å‚æ•° (8ç»´)
    "device_params": [temp, freq, ...],  # å½’ä¸€åŒ–çš„è®¾å¤‡å‚æ•°

    # ç´¯è®¡èŠ‚èƒ½ (1ç»´)
    "cumulative_saving": 12500,  # å…ƒ

    # è¾¾æˆç‡ (1ç»´)
    "achievement_rate": 0.85,

    # è¾¾æˆç‡å†å² (10ç»´)
    "achievement_history": [0.8, 0.82, ..., 0.85]
}

# æ€»ç»´åº¦: 16 + 1 + 10 + 8 + 1 + 1 + 10 = 47ç»´
```

### çŠ¶æ€å½’ä¸€åŒ–

æ‰€æœ‰çŠ¶æ€å€¼å½’ä¸€åŒ–åˆ° [0, 1] åŒºé—´:

```python
def normalize_state(raw_state):
    normalized = {}

    # è´Ÿè·: é™¤ä»¥æœ€å¤§éœ€é‡
    normalized["load_data"] = raw_state["load_data"] / max_demand

    # ç”µä»·æ—¶æ®µ: one-hot æˆ– ç›´æ¥ / 4
    normalized["price_period"] = raw_state["price_period"] / 4

    # è¾¾æˆç‡: å·²ç»æ˜¯ 0-1
    normalized["achievement_rate"] = raw_state["achievement_rate"]

    return normalized
```

---

## åŠ¨ä½œç©ºé—´è®¾è®¡ (S5e)

### è¿ç»­åŠ¨ä½œç©ºé—´

```python
actions = {
    # æ¸©åº¦è°ƒæ•´ [-1, 1] â†’ [-1â„ƒ, +1â„ƒ]
    "temp_adjustment": 0.3,  # è¡¨ç¤º +0.3â„ƒ

    # åŠŸç‡åˆ†é… [-1, 1] â†’ [-10%, +10%]
    "power_rebalance": -0.2,  # è¡¨ç¤º -2%

    # æ—¶æ®µåç§» [-1, 1] â†’ [-60min, +60min]
    "time_shift": 0.5,  # è¡¨ç¤º +30min

    # è®¾å¤‡ä¼˜å…ˆçº§ [0, 1] â†’ è°ƒæ•´å¯åœé¡ºåº
    "device_priority": [0.8, 0.2, 0.6, ...]
}
```

### åŠ¨ä½œè§£ç ç¤ºä¾‹

```python
def decode_actions(raw_actions):
    adjustments = {}

    # æ¸©åº¦è°ƒæ•´
    adjustments["target_temp"] = current_temp + raw_actions["temp_adjustment"] * 1.0

    # åŠŸç‡é‡åˆ†é…
    for i, device in enumerate(devices):
        delta = raw_actions["power_rebalance"] * 0.1 * device.rated_power
        adjustments[device.id] = {"power_delta": delta}

    # æ—¶æ®µåç§»
    adjustments["shift_time"] = current_time + raw_actions["time_shift"] * 60  # åˆ†é’Ÿ

    return adjustments
```

---

## å¥–åŠ±å‡½æ•°è®¾è®¡

### åŸºç¡€å¥–åŠ±å…¬å¼

```
R = Î± Ã— achievement_rate - Î² Ã— comfort_penalty - Î³ Ã— safety_penalty

å…¶ä¸­:
Î± = 1.0      (è¾¾æˆç‡æƒé‡)
Î² = 0.2      (èˆ’é€‚åº¦æƒ©ç½šæƒé‡)
Î³ = 0.4      (å®‰å…¨æƒ©ç½šæƒé‡)
```

### æƒ©ç½šé¡¹è®¡ç®—

```python
def compute_penalties(state, action):
    # èˆ’é€‚åº¦æƒ©ç½š: æ¸©åº¦åç¦»èˆ’é€‚åŒº
    temp_deviation = abs(actual_temp - comfort_temp)
    comfort_penalty = min(temp_deviation / 2.0, 1.0)  # åç¦»2â„ƒæ»¡æƒ©ç½š

    # å®‰å…¨æƒ©ç½š: å‘Šè­¦è§¦å‘
    alarm_count = get_alarm_count_since_action()
    safety_penalty = min(alarm_count / 5.0, 1.0)  # 5æ¬¡å‘Šè­¦æ»¡æƒ©ç½š

    return comfort_penalty, safety_penalty
```

### å¥–åŠ±ç¤ºä¾‹

| åœºæ™¯ | è¾¾æˆç‡ | èˆ’é€‚åº¦æƒ©ç½š | å®‰å…¨æƒ©ç½š | å¥–åŠ±R |
|------|--------|-----------|----------|-------|
| ç†æƒ³æƒ…å†µ | 100% | 0 | 0 | 1.0 |
| è‰¯å¥½ | 90% | 0.1 | 0 | 0.88 |
| æœ‰é—®é¢˜ | 80% | 0.3 | 0.2 | 0.66 |
| å¤±è´¥ | 50% | 0.5 | 0.5 | 0.2 |

---

## æ¢ç´¢ç‡è°ƒæ•´ (S5f)

### è¡°å‡ç­–ç•¥

```python
class ExplorationScheduler:
    def __init__(self):
        self.epsilon = 0.3       # åˆå§‹æ¢ç´¢ç‡
        self.epsilon_min = 0.05  # æœ€å°æ¢ç´¢ç‡
        self.decay = 0.995       # è¡°å‡ç³»æ•°

    def step(self, achievement_rate):
        # åŸºç¡€è¡°å‡
        self.epsilon = max(self.epsilon * self.decay, self.epsilon_min)

        # è‡ªé€‚åº”è°ƒæ•´: è¾¾æˆç‡ä½æ—¶å¢åŠ æ¢ç´¢
        if achievement_rate < 0.7:
            self.epsilon = min(self.epsilon * 1.2, 0.3)

        return self.epsilon
```

### æ¢ç´¢é˜¶æ®µåˆ¤æ–­

| æ¢ç´¢ç‡èŒƒå›´ | é˜¶æ®µ | å»ºè®®é‡‡çº³ç¨‹åº¦ |
|-----------|------|-------------|
| > 0.2 | åˆæœŸæ¢ç´¢ | ä»…ä¾›å‚è€ƒ |
| 0.1 - 0.2 | è¿‡æ¸¡æœŸ | å®¡æ…é‡‡çº³ |
| < 0.1 | ç¨³å®šæœŸ | å»ºè®®é‡‡çº³ |

---

## åœ¨çº¿å­¦ä¹ æµç¨‹

### ç»éªŒæ”¶é›†

```python
experience = {
    "state": current_state,
    "action": selected_action,
    "reward": computed_reward,
    "next_state": next_state,
    "done": is_episode_done
}

replay_buffer.add(experience)
```

### ç½‘ç»œæ›´æ–°

```python
def train_step(batch_size=32):
    # ä»ç¼“å†²åŒºé‡‡æ ·
    batch = replay_buffer.sample(batch_size)

    # è®¡ç®—TDç›®æ ‡
    with torch.no_grad():
        next_values = critic(batch.next_states)
        td_targets = batch.rewards + gamma * next_values

    # æ›´æ–°Critic
    critic_loss = F.mse_loss(critic(batch.states), td_targets)
    critic_optimizer.step(critic_loss)

    # æ›´æ–°Actor (ç­–ç•¥æ¢¯åº¦)
    actor_loss = -critic(batch.states, actor(batch.states)).mean()
    actor_optimizer.step(actor_loss)

    return {"critic_loss": critic_loss, "actor_loss": actor_loss}
```

---

## APIæ¥å£

| æ¥å£ | æ–¹æ³• | è¯´æ˜ |
|------|------|------|
| `/proposals/{id}/rl/optimize` | POST | è·å–ä¼˜åŒ–å»ºè®® |
| `/proposals/{id}/rl/status` | GET | è·å–RLçŠ¶æ€ |
| `/proposals/{id}/rl/apply/{opt_id}` | POST | åº”ç”¨ä¼˜åŒ–å»ºè®® |
| `/proposals/rl/train` | POST | è§¦å‘è®­ç»ƒæ­¥éª¤ |
| `/proposals/rl/model-info` | GET | è·å–æ¨¡å‹ä¿¡æ¯ |
| `/proposals/rl/exploration-rate` | PUT | æ‰‹åŠ¨è°ƒæ•´æ¢ç´¢ç‡ |

---

## æœ€ä½³å®è·µ

### 1. ä½•æ—¶è§¦å‘RLä¼˜åŒ–

âœ… æ¨èåœºæ™¯:
- è¾¾æˆç‡æŒç»­ä½äº80%
- å¤–éƒ¨æ¡ä»¶æ˜¾è‘—å˜åŒ– (å­£èŠ‚ã€è´Ÿè½½)
- æ–°æªæ–½ä¸Šçº¿è¿è¡Œ2å‘¨å

âŒ ä¸æ¨èåœºæ™¯:
- è¾¾æˆç‡å·²è¶…90%
- æ¢ç´¢ç‡ > 0.2 (åˆæœŸ)
- æ— è¶³å¤Ÿç›‘æµ‹æ•°æ®

### 2. å¦‚ä½•è¯„ä¼°å»ºè®®è´¨é‡

```
å»ºè®®å¯ä¿¡åº¦ = 1 - exploration_rate

if confidence > 0.9:
    "é«˜å¯ä¿¡åº¦ï¼Œå»ºè®®é‡‡çº³"
elif confidence > 0.8:
    "ä¸­å¯ä¿¡åº¦ï¼Œå®¡æ…è¯„ä¼°"
else:
    "ä½å¯ä¿¡åº¦ï¼Œä»…ä¾›å‚è€ƒ"
```

### 3. å¼‚å¸¸æƒ…å†µå¤„ç†

- **å»ºè®®ä¸å®‰å…¨è§„èŒƒå†²çª**: è‡ªåŠ¨è¿‡æ»¤ï¼Œä¸æ¨é€
- **è¿ç»­å¤šæ¬¡è´Ÿå¥–åŠ±**: è§¦å‘æ¨¡å‹æ£€æŸ¥å‘Šè­¦
- **æ¢ç´¢ç‡å¼‚å¸¸å‡é«˜**: å¯èƒ½å­˜åœ¨ç¯å¢ƒå‰§å˜ï¼Œéœ€äººå·¥ä»‹å…¥

---

## ç›¸å…³æ–‡æ¡£

- [èŠ‚èƒ½æ–¹æ¡ˆæ“ä½œæŒ‡å—](../2-user-guides/energy-manager/proposal-workflow.md)
- [èŠ‚èƒ½æ–¹æ¡ˆæµç¨‹](./energy-saving-flow.md)
- [è®¡ç®—å…¬å¼å‚è€ƒ](../4-data-guides/formula-reference.md)
